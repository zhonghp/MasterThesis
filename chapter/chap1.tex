\rhead{\xiaowuhao{\sectionindex\quad绪论}}
\section{绪论}

\subsection{研究背景和意义}
在数字信息爆炸式增长的今天，搜索引擎无疑是人们获取信息资源的主要途径。根据Google提供的数据，2014年Google平均每天接收到的查询请求数已经超过了57亿次，2014年Google接收到的查询总数已经高达2万亿次 \footnote{数据来自Google Official History, ComScore}。自从搜索引擎出现以来，如何能够根据用户输入的查询词准确地捕捉到用户的查询意图，一直是搜索引擎面临的挑战和亟待解决的难题。

2012年5月，Google首次在它的搜索页面中推出了知识图谱(Knowledge Graph)，用户在使用Google进行搜索时，除了能够获得相关的网页链接以外，还将得到更加结构化的相关信息。例如，用户在输入“Barack Obama”后，谷歌不仅会提供相关的网络链接，还会在页面的右侧提供奥巴马的详细信息，包括个人简介、出生时间及地点等，具体如图\ref{knowledgegraph}所示。知识图谱的出现大大缩小了用户查找信息的范围，当用户希望获取相关信息时，不再需要自己动手访问搜索引擎返回的网页。

%%%TODO%%%
\begin{figure}[h]
  \centering
  \subfigure[]{\includegraphics[width=0.75\columnwidth]{figures/pic1.eps}}
  \caption{谷歌的知识图谱示例}
  \label{knowledgegraph}
\end{figure}

知识图谱中最重要的数据来源便是大规模的知识库，如维基百科等。知识库是由描述事实的三元组组成，其中包含了大量的结构化知识。知识库中的每个三元组将实体之间的关系表示为（头部实体，关系，尾部实体），如（中国，首都，北京）等。正因为知识库包含着大量结构化的事实性知识，其在许多人工智能系统中都有着广泛的应用，如：查询扩展\cite{}、问答系统\cite{}、文本理解\cite{}等。尽管国内外已经存在着许多大规模的知识库，如：WordNet\cite{}、Yago\cite{}、Freebase\cite{}等。但是，有限的覆盖率问题始终制约着知识库的使用与发展\cite{}。除此之外，如何在计算机中表示和存储知识库，也是知识库应用中的重要一环。

与结构化的知识库不同的是，随着Web2.0的兴起，互联网上涌现了大量的无标注文本数据。近年来，得益于深度学习\cite{}的发展，基于神经网络的表示学习方法使得计算机可以从大规模的无标注文本数据中自动学习得到文本的向量表示，并在许多自然语言处理领域的问题上取得了突破性的进展\cite{}。受到无标注文本中基于神经网络的表示方法鼓舞，研究人员开始探索面向知识库的表示学习方法，并尝试将知识库与文本进行联合式的表示学习，有效地解决了知识库的低覆盖率问题\cite{}。然而，知识库与文本的联合表示学习方法现在还比较少，而且已有的学习方法存在着一定的缺陷。因此，研究这一课题不仅有着很大的应用前景，也有着相当大的研究价值。

\subsection{国内外研究现状}
本文主要研究如何对知识库和文本的向量表示进行联合式学习，通过合适的对齐模型使得知识库中的实体向量和关系向量与文本中的词向量位于同一个向量空间中，从而进行不局限于知识库的知识推理，有效地解决知识库的低覆盖率问题。目前，国内外研究这一课题的工作还比较少，\cite{}首次提出了知识库与文本的联合表示的概念，并设计出了包含知识库模型、文本模型和对齐模型的学习框架，具体如下所示：
\begin{enumerate}
  \item 知识库模型：根据知识库中已有的三元组，学习出实体和关系的向量表示，进而可以量化给定三元组的可信度；
  \item 文本模型：根据语料库中词与词的共现情况，学习出词的向量表示，使得语义比较相关的词有着比较相似的向量表示；
  \item 对齐模型：对上述两个模型中学习得到的实体向量和词向量进行对齐，使得知识库的向量表示和文本的向量表示能够位于同一个向量空间中。
\end{enumerate}

其中，国内外研究人员对知识库模型和文本模型的研究比较深入，而且有了比较成型的研究成果和工具。相反，关于对齐模型的研究目前还比较少。本节将对此进行详细的介绍。

\subsubsection{知识库模型的研究}
近年来，随着神经网络和深度学习的革命性发展，知识库模型也受到了研究人员的关注。知识库模型指的是面向知识库的表示学习方法，其主要是通过低维度的稠密向量表征出知识库中的实体和关系的语义信息，这种表示也称为知识库嵌入（Knowledge Base Embeddings），这种表示能够极大地帮助计算机表示和存储知识库。

其中，Bordes等人提出的TransE模型便是最具代表性的工作。对于知识库中的任意三元组$(h,r,t)$，$h$是头部实体（head entity）、$r$是关系（relation）、$t$是尾部实体（tail entity），TransE把关系$r$的向量表示$\mathbf{r}$看作是从实体$h$的向量表示$\mathbf{h}$到实体$t$的向量表示$\mathbf{t}$的平移，并通过不断调整$\mathbf{h}$、$\mathbf{r}$和$\mathbf{t}$，使得$(\mathbf{h}+\mathbf{r})$尽可能与$\mathbf{t}$相等，即$\mathbf{h}+\mathbf{r} \approx \mathbf{t}$。通过优化上述目标，TransE能够有效地学习出实体和关系的向量表示，使得如果一个候选三元组$(h,r,t)$是有效的，那么$(\mathbf{h}+\mathbf{r})$将与$\mathbf{t}$十分相近。因此，TransE根据公式\ref{eqn:transe}对三元组$(h,r,t)$进行评分，如果$(h,r,t)$是有效的，$f_r(h,t)$将会很小。通过$f_r(h,t)$的定义，TransE能够帮助知识库进行知识推理，进而有效地缓解知识库的低覆盖率问题。\cite{}中的实验也证明了TransE有着比传统方法更优的性能，因此很多工作就此展开。
\begin{equation}
  f_r(h,t)=\|\mathbf{h}+\mathbf{r}-\mathbf{t}\|_2^2
  \label{eqn:transe}
\end{equation}

由于TransE的模型过于简单，使得它只能在处理一对一（1-to-1）这种类型的关系时取得比较好的效果，并不能很好地表示一对多（1-to-N）、多对一（N-to-1）以及多对多（N-to-N）类型的关系。例如，对于一个多对一的关系$r$，$\forall i \in \{ 0, ..., m \}$，$(h_i, r, t)$都是有效的，TransE的模型会使得$\mathbf{h_0}=...=\mathbf{h_m}$，这显然是不合理的。为了解决TransE在表示这些关系时的问题，Wang在2014年提出了TransH\cite{}，其主要思想是每一个实体在对于不同的关系时都会有不同的向量表示，每个关系向量都有自己特定的超平面。对于任意一个关系$r$，TransH不仅会学习它的向量表示$\mathbf{r}$，还会学习出它所位于超平面的法向量表示$\mathbf{w_r}$。对于给定的三元组$(h,r,t)$，TransH首先会将实体向量$\mathbf{h}$和$\mathbf{t}$投影到关系$r$的超平面中，得到向量$\mathbf{h_r}$和$\mathbf{h_t}$，其中$\mathbf{h_r}=\mathbf{h}-\mathbf{w_r}^\top\mathbf{h}\mathbf{w_r}$、$\mathbf{t_r}=\mathbf{t}-\mathbf{w_r}^\top\mathbf{t}\mathbf{w_r}$。因此，TransH根据公式\ref{eqn:transh}对三元组进行评分。
\begin{equation}
  f_r(h,t)=\|\mathbf{h_r}+\mathbf{r}-\mathbf{t_r}\|_2^2
  \label{eqn:transh}
\end{equation}

通过修改TransE的评分函数和目标函数，Wang
\subsubsection{文本模型的研究}
\subsubsection{对齐模型的研究}

\subsection{论文内容和结构}