% 请在 ENabstract 环境中输入英文摘要的内容。
\lhead{\xiaowuhao\enthesistitle}
\chead{}
\rhead{\xiaowuhao Abstract}
\begin{ENabstract}
\begin{spacing}{1.5}

With the explosive growth of network information, search engine has already become an indispensable tool for people to obtain information and knowledge. The search engine always works like that: it returns the most relevant web pages according to the web queries provided by users. The traditional search engine simply matches the query words and web pages, it cannot understand the users' intent behind the web queries. How to make itself become more intelligent has already become an urgent problem each search engine must solve.

Since Google proposed the Knowledge Graph, knowledge base has brought hope for the intelligent search engine. Users can not only obtain the relevant web page, but also get more intelligent information when using the search engine. Generally, a knowledge base consists of billions of fact triplets, which contains a large number of entities and the rich relations between them. Although knowledge base has been widely used in many AI systems, it still suffers from its limited coverage.

To effectively address the limited coverage problem in knowledge base, we propose a novel method to jointly embed knowledge base and text into the same continuous low-dimensional vector space so as to help the knowledge base to reason new facts. We require the embedding vector
of an entity not only to fit the structured constraints in KB but also to be equal to the embedding vector computed from the text description. In contrast to the previous methods, our model not only can reason the missing facts which contain entities out of the knowledge base, but also does not need and manually labeled information.

In order to prove the effectiveness of our method, we conduct extensive standard experiments on the existed datasets, including link prediction,
triple classification and analogical reasoning. We also verify whether our model is practical by means of the improving relational fact extraction task. All these show that our model outperforms the state-of-the-art baseline systems.

\end{spacing}
\end{ENabstract}

% 请在 \enkeywd{} 的参数中加入关键词。
% 所有的 \enkeywd 命令必须在 ENabstract 环境后面调用。

% 每一个关键词调用一次 \enkeywd 命令。命令的闭合花括号后面应当紧跟着注释符号（即
% "%"），否则会在顿号前面增加一个空格。
\begin{spacing}{1.5}
\enkeywd{Search Engine}% 填入一条关键词
\enkeywd{Knowledge Base}%
\enkeywd{Text}%
\enkeywd{Jointly Embedding}%
\enkeywd{Knowledge Reasoning}
\end{spacing} 